{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a014b07d",
   "metadata": {},
   "source": [
    "# RAG for Document Quality Improvement\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** combines information retrieval with LLM generation to produce better outputs.\n",
    "\n",
    "## The Problem\n",
    "\n",
    "Our DocumentGenerator agent creates bid documents, but they're generic. The LLM doesn't know:\n",
    "- What good procurement documents look like for our domain\n",
    "- Common patterns in successful bids\n",
    "- Domain-specific terminology and structure\n",
    "\n",
    "**Result**: Documents are grammatically correct but lack the quality and specificity of human-written bids.\n",
    "\n",
    "## The Solution: RAG\n",
    "\n",
    "Instead of generating from scratch, we:\n",
    "1. **Build a knowledge base** of high-quality example documents\n",
    "2. **Retrieve relevant examples** similar to the current tender\n",
    "3. **Augment the prompt** with these examples before generation\n",
    "\n",
    "This teaches the LLM by example, dramatically improving output quality.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll understand:\n",
    "1. How RAG works (theory ‚Üí practice)\n",
    "2. Building and querying vector databases\n",
    "3. Embeddings and similarity search\n",
    "4. Prompt augmentation techniques\n",
    "5. Measuring RAG impact on output quality\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eec96c",
   "metadata": {},
   "source": [
    "## Part 1: Understanding RAG\n",
    "\n",
    "### Traditional Generation (No RAG)\n",
    "\n",
    "```\n",
    "User: \"Generate a bid for cybersecurity tender\"\n",
    "       ‚Üì\n",
    "LLM: Uses only its training data\n",
    "       ‚Üì\n",
    "Output: Generic security document\n",
    "```\n",
    "\n",
    "**Problem**: LLM has general knowledge but not your specific domain expertise.\n",
    "\n",
    "### RAG-Enhanced Generation\n",
    "\n",
    "```\n",
    "User: \"Generate a bid for cybersecurity tender\"\n",
    "       ‚Üì\n",
    "1. Search knowledge base for similar tenders\n",
    "       ‚Üì\n",
    "2. Retrieve: 3 high-quality cybersecurity bid examples\n",
    "       ‚Üì\n",
    "3. Augment prompt with retrieved examples\n",
    "       ‚Üì\n",
    "LLM: \"Here are examples of excellent bids... Now generate:\"\n",
    "       ‚Üì\n",
    "Output: Domain-specific, high-quality document\n",
    "```\n",
    "\n",
    "**Key insight**: RAG gives the LLM access to your institutional knowledge.\n",
    "\n",
    "### How Similarity Search Works\n",
    "\n",
    "Question: How do we find \"similar\" documents?\n",
    "\n",
    "Answer: **Embeddings** - convert text into numerical vectors that capture meaning.\n",
    "\n",
    "```\n",
    "Text: \"AI cybersecurity threat detection\"\n",
    "  ‚Üì (embedding model)\n",
    "Vector: [0.23, -0.45, 0.89, ..., 0.12]  (1536 dimensions)\n",
    "\n",
    "Text: \"ML-based security monitoring\"\n",
    "  ‚Üì (embedding model)\n",
    "Vector: [0.25, -0.43, 0.91, ..., 0.15]  (similar!)\n",
    "\n",
    "Text: \"Office furniture procurement\"\n",
    "  ‚Üì (embedding model)\n",
    "Vector: [-0.67, 0.12, -0.34, ..., 0.78]  (very different)\n",
    "```\n",
    "\n",
    "Similar concepts have similar vectors. We measure similarity using **cosine similarity**:\n",
    "- 1.0 = identical\n",
    "- 0.9+ = very similar\n",
    "- 0.7-0.9 = somewhat similar\n",
    "- <0.5 = unrelated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ffc593",
   "metadata": {},
   "source": [
    "## Part 2: Setting Up the Environment\n",
    "\n",
    "We'll use:\n",
    "- **ChromaDB**: Simple, fast vector database (no server needed)\n",
    "- **OpenAI Embeddings**: Convert text to vectors (via our LM Studio endpoint)\n",
    "- **Existing agents**: Filter and DocumentGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de019389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import asyncio\n",
    "from typing import List, Dict\n",
    "from procurement_ai.config import Config\n",
    "\n",
    "# Initialize\n",
    "config = Config()\n",
    "\n",
    "print(\"‚úÖ RAG environment initialized!\")\n",
    "print(f\"LLM Endpoint: {config.LLM_BASE_URL}\")\n",
    "print(f\"Model: {config.LLM_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844dbe4",
   "metadata": {},
   "source": [
    "## Part 3: Building a Knowledge Base\n",
    "\n",
    "First, let's create sample high-quality documents. In production, these would be real successful bids.\n",
    "\n",
    "### What Makes a Good Knowledge Base Entry?\n",
    "\n",
    "Each document should have:\n",
    "1. **Content**: The actual high-quality text\n",
    "2. **Metadata**: Category, success rate, date (for filtering)\n",
    "3. **Context**: When/why this example is relevant\n",
    "\n",
    "Let's create 5-6 examples covering different procurement categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample knowledge base: high-quality bid excerpts\n",
    "KNOWLEDGE_BASE = [\n",
    "    {\n",
    "        \"id\": \"kb_001\",\n",
    "        \"category\": \"cybersecurity\",\n",
    "        \"title\": \"AI-Powered Threat Detection Implementation\",\n",
    "        \"content\": \"\"\"## Executive Summary\n",
    "\n",
    "Our proposed solution delivers enterprise-grade threat detection leveraging machine learning algorithms specifically tuned for government security requirements. The system processes 10M+ events daily, automatically categorizing threats by severity and triggering appropriate response protocols.\n",
    "\n",
    "## Technical Approach\n",
    "\n",
    "We employ a three-tier detection architecture:\n",
    "\n",
    "1. **Real-time Pattern Recognition**: Neural network models trained on 5+ years of government sector threat data, achieving 99.2% accuracy with <0.1% false positive rate.\n",
    "\n",
    "2. **Behavioral Analytics**: Anomaly detection using unsupervised learning to identify zero-day threats and insider risks before they escalate.\n",
    "\n",
    "3. **Automated Response**: Integration with existing SIEM infrastructure, enabling immediate containment actions while alerting security teams.\n",
    "\n",
    "## Implementation Timeline\n",
    "\n",
    "Phase 1 (Weeks 1-4): Infrastructure setup and data integration\n",
    "Phase 2 (Weeks 5-8): Model training and validation\n",
    "Phase 3 (Weeks 9-12): Deployment and team training\n",
    "\n",
    "## Compliance & Certification\n",
    "\n",
    "Our team holds ISO 27001, SOC 2 Type II, and government clearance. All data processing occurs on-premises, ensuring complete data sovereignty.\"\"\",\n",
    "        \"success_rate\": 0.95,\n",
    "        \"year\": 2025\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"kb_002\",\n",
    "        \"category\": \"ai\",\n",
    "        \"title\": \"Predictive Maintenance AI Platform\",\n",
    "        \"content\": \"\"\"## Solution Overview\n",
    "\n",
    "Our predictive maintenance platform reduces equipment downtime by 40% through advanced AI-driven failure prediction. The system monitors 200+ sensor parameters in real-time, predicting failures 72 hours in advance with 94% accuracy.\n",
    "\n",
    "## Technical Architecture\n",
    "\n",
    "Built on proven open-source frameworks (TensorFlow, FastAPI), ensuring full transparency and no vendor lock-in. The platform consists of:\n",
    "\n",
    "**Data Pipeline**: Ingests sensor data at 1000 Hz, processes using Apache Kafka for real-time streaming\n",
    "\n",
    "**ML Models**: Ensemble of LSTM networks and Random Forests, retrained weekly with new operational data\n",
    "\n",
    "**Alert System**: Multi-channel notifications (email, SMS, dashboard) with configurable thresholds\n",
    "\n",
    "## Business Value\n",
    "\n",
    "Based on pilot deployments:\n",
    "- 40% reduction in unplanned downtime\n",
    "- 25% decrease in maintenance costs\n",
    "- ROI achieved within 8 months\n",
    "\n",
    "## Team Expertise\n",
    "\n",
    "Our engineers have deployed AI systems in 15+ industrial facilities. Lead architect: PhD in ML from MIT, 10 years industry experience.\"\"\",\n",
    "        \"success_rate\": 0.88,\n",
    "        \"year\": 2025\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"kb_003\",\n",
    "        \"category\": \"software\",\n",
    "        \"title\": \"Custom CRM System Development\",\n",
    "        \"content\": \"\"\"## Project Scope\n",
    "\n",
    "We will develop a cloud-native CRM system tailored to your organization's unique workflow, replacing legacy systems while preserving 15 years of customer data integrity.\n",
    "\n",
    "## Development Methodology\n",
    "\n",
    "**Agile with Weekly Sprints**: Client reviews every Friday, ensuring alignment and early issue detection\n",
    "\n",
    "**Technology Stack**:\n",
    "- Frontend: React with TypeScript for type safety\n",
    "- Backend: Python FastAPI, PostgreSQL database\n",
    "- Cloud: AWS with auto-scaling (handles 10x traffic spikes)\n",
    "- Security: OAuth2, encryption at rest and in transit\n",
    "\n",
    "## Migration Strategy\n",
    "\n",
    "Zero data loss guaranteed:\n",
    "1. Automated backup before each migration step\n",
    "2. Parallel running (old and new systems) for 30 days\n",
    "3. Validation: 100% data reconciliation before legacy shutdown\n",
    "\n",
    "## Support & Maintenance\n",
    "\n",
    "Year 1: Included in project cost (24/7 support)\n",
    "Year 2+: Optional SLA packages (99.9% uptime guarantee)\n",
    "\n",
    "## References\n",
    "\n",
    "Similar CRM projects completed for [Client A] and [Client B], both reporting >30% productivity gains post-implementation.\"\"\",\n",
    "        \"success_rate\": 0.92,\n",
    "        \"year\": 2024\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"kb_004\",\n",
    "        \"category\": \"data_analytics\",\n",
    "        \"title\": \"Business Intelligence Dashboard Suite\",\n",
    "        \"content\": \"\"\"## Vision\n",
    "\n",
    "Transform your raw operational data into actionable insights with real-time dashboards that executives actually use. Our BI platform consolidates 15 data sources into unified, drill-down visualizations.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "**Executive Dashboard**: 6 KPIs updated every 5 minutes\n",
    "- Revenue trends with forecasting\n",
    "- Operational efficiency metrics\n",
    "- Customer satisfaction tracking\n",
    "\n",
    "**Departmental Views**: Customized for sales, operations, finance\n",
    "\n",
    "**Mobile-First Design**: Full functionality on tablets and phones\n",
    "\n",
    "## Technical Implementation\n",
    "\n",
    "Built on Tableau/Power BI (client preference), with custom connectors for your ERP, CRM, and legacy systems.\n",
    "\n",
    "**Data Pipeline**: ETL processes running hourly, validating data quality at each step\n",
    "\n",
    "**Performance**: 2-second load times even with 5-year historical data\n",
    "\n",
    "## Training & Adoption\n",
    "\n",
    "3-day workshop for power users + recorded tutorials for all staff. Our track record: 85% adoption rate within first month.\"\"\",\n",
    "        \"success_rate\": 0.87,\n",
    "        \"year\": 2025\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"kb_005\",\n",
    "        \"category\": \"cloud\",\n",
    "        \"title\": \"Cloud Migration and Infrastructure Modernization\",\n",
    "        \"content\": \"\"\"## Migration Strategy\n",
    "\n",
    "We execute low-risk, phased cloud migrations that maintain business continuity. No downtime for critical services.\n",
    "\n",
    "## Assessment Phase (Weeks 1-2)\n",
    "\n",
    "- Inventory all applications and dependencies\n",
    "- Categorize by migration complexity (lift-and-shift vs. re-architecture)\n",
    "- Identify cost optimization opportunities\n",
    "\n",
    "## Migration Approach\n",
    "\n",
    "**Wave 1**: Non-critical systems (build confidence)\n",
    "**Wave 2**: Business applications (during low-usage windows)\n",
    "**Wave 3**: Mission-critical services (with full rollback plans)\n",
    "\n",
    "## Cloud Architecture\n",
    "\n",
    "**Multi-AZ Deployment**: High availability across 3 availability zones\n",
    "**Auto-Scaling**: Handles traffic spikes automatically, reduces costs during low usage\n",
    "**Disaster Recovery**: RPO=1 hour, RTO=4 hours\n",
    "\n",
    "## Cost Governance\n",
    "\n",
    "Budget alerts, rightsizing recommendations, and reserved instance strategies typically reduce cloud spend by 30-40% compared to on-demand pricing.\n",
    "\n",
    "## Security & Compliance\n",
    "\n",
    "All cloud resources configured following CIS benchmarks. Continuous compliance monitoring via AWS Security Hub / Azure Security Center.\"\"\",\n",
    "        \"success_rate\": 0.91,\n",
    "        \"year\": 2025\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Knowledge base created with {len(KNOWLEDGE_BASE)} high-quality examples\")\n",
    "print(\"\\nCategories:\")\n",
    "for doc in KNOWLEDGE_BASE:\n",
    "    print(f\"  - {doc['category']}: {doc['title']} (Success rate: {doc['success_rate']:.0%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ee733",
   "metadata": {},
   "source": [
    "## Part 4: Creating Embeddings\n",
    "\n",
    "Now we convert each document into a vector (embedding). This lets us perform similarity search.\n",
    "\n",
    "### What Are Embeddings?\n",
    "\n",
    "Think of embeddings as \"GPS coordinates\" for meaning:\n",
    "- Similar concepts are close together in vector space\n",
    "- Unrelated concepts are far apart\n",
    "- The model learned these relationships from massive text datasets\n",
    "\n",
    "We'll use our local LLM's embedding endpoint (compatible with OpenAI API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc371a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "class EmbeddingService:\n",
    "    \"\"\"Simple wrapper for creating text embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.base_url = config.LLM_BASE_URL\n",
    "        \n",
    "    async def create_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Create embedding for a single text\"\"\"\n",
    "        async with httpx.AsyncClient(timeout=30.0) as client:\n",
    "            response = await client.post(\n",
    "                f\"{self.base_url}/embeddings\",\n",
    "                json={\n",
    "                    \"input\": text,\n",
    "                    \"model\": self.config.LLM_MODEL\n",
    "                }\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            return data['data'][0]['embedding']\n",
    "    \n",
    "    async def create_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Create embeddings for multiple texts\"\"\"\n",
    "        # Process in batch for efficiency\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            emb = await self.create_embedding(text)\n",
    "            embeddings.append(emb)\n",
    "        return embeddings\n",
    "\n",
    "# Initialize\n",
    "embedding_service = EmbeddingService(config)\n",
    "\n",
    "# Test it\n",
    "test_text = \"AI-powered cybersecurity threat detection system\"\n",
    "test_embedding = await embedding_service.create_embedding(test_text)\n",
    "\n",
    "print(f\"‚úÖ Embedding service working!\")\n",
    "print(f\"   Text: '{test_text}'\")\n",
    "print(f\"   Embedding dimensions: {len(test_embedding)}\")\n",
    "print(f\"   First 5 values: {test_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de296732",
   "metadata": {},
   "source": [
    "### Understanding Cosine Similarity\n",
    "\n",
    "To find similar documents, we compare their embeddings using cosine similarity:\n",
    "\n",
    "```\n",
    "similarity = dot_product(vec1, vec2) / (||vec1|| * ||vec2||)\n",
    "```\n",
    "\n",
    "Result is between -1 and 1:\n",
    "- **1.0**: Identical meaning\n",
    "- **0.9-1.0**: Very similar\n",
    "- **0.7-0.9**: Somewhat related\n",
    "- **<0.5**: Unrelated\n",
    "\n",
    "Let's implement it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a3af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    vec1_np = np.array(vec1)\n",
    "    vec2_np = np.array(vec2)\n",
    "    \n",
    "    dot_product = np.dot(vec1_np, vec2_np)\n",
    "    norm1 = np.linalg.norm(vec1_np)\n",
    "    norm2 = np.linalg.norm(vec2_np)\n",
    "    \n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# Test similarity between different concepts\n",
    "text1 = \"AI cybersecurity threat detection\"\n",
    "text2 = \"ML-based security monitoring system\"\n",
    "text3 = \"Office furniture and interior design\"\n",
    "\n",
    "emb1 = await embedding_service.create_embedding(text1)\n",
    "emb2 = await embedding_service.create_embedding(text2)\n",
    "emb3 = await embedding_service.create_embedding(text3)\n",
    "\n",
    "sim_1_2 = cosine_similarity(emb1, emb2)\n",
    "sim_1_3 = cosine_similarity(emb1, emb3)\n",
    "\n",
    "print(\"üìä Similarity Test:\")\n",
    "print(f\"\\n  '{text1}'\")\n",
    "print(f\"  vs\")\n",
    "print(f\"  '{text2}'\")\n",
    "print(f\"  ‚Üí Similarity: {sim_1_2:.3f} (Very similar! ‚úÖ)\\n\")\n",
    "\n",
    "print(f\"  '{text1}'\")\n",
    "print(f\"  vs\")\n",
    "print(f\"  '{text3}'\")\n",
    "print(f\"  ‚Üí Similarity: {sim_1_3:.3f} (Very different, as expected ‚úÖ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8eb0ba",
   "metadata": {},
   "source": [
    "## Part 5: Building the Vector Store\n",
    "\n",
    "Now let's store our knowledge base documents with their embeddings in ChromaDB.\n",
    "\n",
    "### Why Use a Vector Database?\n",
    "\n",
    "We could calculate similarity against every document manually, but:\n",
    "- Slow with 1000+ documents\n",
    "- Need to recompute every query\n",
    "\n",
    "Vector databases like Chroma:\n",
    "- Index embeddings for fast search (milliseconds)\n",
    "- Handle filtering by metadata\n",
    "- Persist data to disk\n",
    "\n",
    "Let's set it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14967ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ChromaDB if needed\n",
    "# !pip install chromadb\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Initialize Chroma (in-memory for this notebook)\n",
    "chroma_client = chromadb.Client(Settings(\n",
    "    anonymized_telemetry=False,\n",
    "    allow_reset=True\n",
    "))\n",
    "\n",
    "# Create or get collection\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"procurement_knowledge_base\",\n",
    "    metadata={\"description\": \"High-quality bid examples for RAG\"}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ChromaDB initialized\")\n",
    "print(f\"   Collection: {collection.name}\")\n",
    "print(f\"   Documents: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83abc7b0",
   "metadata": {},
   "source": [
    "### Loading Documents into ChromaDB\n",
    "\n",
    "For each document, we need:\n",
    "1. Document text (what to retrieve)\n",
    "2. Embedding (for similarity search)\n",
    "3. Metadata (for filtering)\n",
    "4. Unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b18154",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_knowledge_base():\n",
    "    \"\"\"Load documents into ChromaDB\"\"\"\n",
    "    \n",
    "    print(\"üîÑ Creating embeddings for knowledge base...\")\n",
    "    print(f\"   (This may take 30-60 seconds for {len(KNOWLEDGE_BASE)} documents)\\n\")\n",
    "    \n",
    "    for i, doc in enumerate(KNOWLEDGE_BASE):\n",
    "        # Create embedding\n",
    "        embedding = await embedding_service.create_embedding(doc['content'])\n",
    "        \n",
    "        # Add to ChromaDB\n",
    "        collection.add(\n",
    "            documents=[doc['content']],\n",
    "            embeddings=[embedding],\n",
    "            metadatas=[{\n",
    "                \"category\": doc['category'],\n",
    "                \"title\": doc['title'],\n",
    "                \"success_rate\": doc['success_rate'],\n",
    "                \"year\": doc['year']\n",
    "            }],\n",
    "            ids=[doc['id']]\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úì {i+1}/{len(KNOWLEDGE_BASE)}: {doc['title']}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Knowledge base loaded: {collection.count()} documents\")\n",
    "\n",
    "# Load it\n",
    "await load_knowledge_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22ecad",
   "metadata": {},
   "source": [
    "## Part 6: Querying the Vector Store\n",
    "\n",
    "Now for the magic: semantic search!\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. User has a tender (e.g., \"AI cybersecurity project\")\n",
    "2. We embed the tender description\n",
    "3. ChromaDB finds documents with similar embeddings\n",
    "4. We get back the most relevant examples\n",
    "\n",
    "Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cada32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_knowledge_base(query: str, n_results: int = 2):\n",
    "    \"\"\"Search for relevant documents\"\"\"\n",
    "    \n",
    "    # Create embedding for query\n",
    "    query_embedding = await embedding_service.create_embedding(query)\n",
    "    \n",
    "    # Search\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test Query 1: Cybersecurity\n",
    "query1 = \"We need to implement AI-based threat detection for government security.\"\n",
    "print(f\"üîç Query: '{query1}'\\n\")\n",
    "\n",
    "results1 = await search_knowledge_base(query1, n_results=2)\n",
    "\n",
    "print(\"Top 2 matches:\")\n",
    "for i, (doc_id, metadata, distance) in enumerate(zip(\n",
    "    results1['ids'][0],\n",
    "    results1['metadatas'][0],\n",
    "    results1['distances'][0]\n",
    ")):\n",
    "    print(f\"\\n{i+1}. {metadata['title']}\")\n",
    "    print(f\"   Category: {metadata['category']}\")\n",
    "    print(f\"   Similarity: {1 - distance:.3f}\")\n",
    "    print(f\"   Content preview: {results1['documents'][0][i][:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Query 2: Software Development\n",
    "query2 = \"Custom CRM application development with cloud hosting\"\n",
    "print(f\"üîç Query: '{query2}'\\n\")\n",
    "\n",
    "results2 = await search_knowledge_base(query2, n_results=2)\n",
    "\n",
    "print(\"Top 2 matches:\")\n",
    "for i, (metadata, distance) in enumerate(zip(\n",
    "    results2['metadatas'][0],\n",
    "    results2['distances'][0]\n",
    ")):\n",
    "    print(f\"\\n{i+1}. {metadata['title']}\")\n",
    "    print(f\"   Category: {metadata['category']}\")\n",
    "    print(f\"   Similarity: {1 - distance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6d624",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Notice how:\n",
    "- Cybersecurity query ‚Üí Cybersecurity document has highest similarity\n",
    "- CRM query ‚Üí Software/Cloud documents rank highest\n",
    "- The model understands semantic relationships (not just keyword matching)\n",
    "\n",
    "This is the power of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b9ba97",
   "metadata": {},
   "source": [
    "## Part 7: RAG-Enhanced Document Generation\n",
    "\n",
    "Now let's put it all together: use retrieved examples to improve document generation.\n",
    "\n",
    "### The RAG Pipeline\n",
    "\n",
    "```python\n",
    "def generate_with_rag(tender):\n",
    "    # 1. Retrieve relevant examples\n",
    "    examples = search_knowledge_base(tender.description)\n",
    "    \n",
    "    # 2. Augment prompt\n",
    "    prompt = f\"\"\"\n",
    "    Here are examples of excellent bids:\n",
    "    {examples}\n",
    "    \n",
    "    Now generate a bid for:\n",
    "    {tender}\n",
    "    \"\"\"\n",
    "    \n",
    "    # 3. Generate\n",
    "    return llm.generate(prompt)\n",
    "```\n",
    "\n",
    "Let's implement it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from procurement_ai.services.llm import LLMService\n",
    "\n",
    "llm = LLMService(config)\n",
    "\n",
    "async def generate_without_rag(tender_description: str) -> str:\n",
    "    \"\"\"Baseline: Generate without RAG\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Generate a professional bid document for this tender:\n",
    "\n",
    "{tender_description}\n",
    "\n",
    "Include:\n",
    "- Executive summary\n",
    "- Technical approach\n",
    "- Timeline\n",
    "- Team qualifications\n",
    "\n",
    "Keep it concise (300-400 words).\"\"\"\n",
    "    \n",
    "    response = await llm.generate(\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "async def generate_with_rag(tender_description: str, n_examples: int = 2) -> str:\n",
    "    \"\"\"Enhanced: Generate with RAG\"\"\"\n",
    "    \n",
    "    # 1. Retrieve relevant examples\n",
    "    results = await search_knowledge_base(tender_description, n_results=n_examples)\n",
    "    \n",
    "    # 2. Format examples\n",
    "    examples_text = \"\"\n",
    "    for i, (doc, meta) in enumerate(zip(results['documents'][0], results['metadatas'][0])):\n",
    "        examples_text += f\"\\n### Example {i+1}: {meta['title']}\\n{doc}\\n\"\n",
    "    \n",
    "    # 3. Augmented prompt\n",
    "    prompt = f\"\"\"You are writing a bid document. First, study these examples of excellent bids:\n",
    "\n",
    "---\n",
    "{examples_text}\n",
    "---\n",
    "\n",
    "Now, using the same level of professionalism and detail as the examples above, generate a bid for:\n",
    "\n",
    "{tender_description}\n",
    "\n",
    "Include:\n",
    "- Executive summary\n",
    "- Technical approach\n",
    "- Timeline\n",
    "- Team qualifications\n",
    "\n",
    "Match the quality and structure of the example documents. Keep it concise (300-400 words).\"\"\"\n",
    "    \n",
    "    response = await llm.generate(\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"‚úÖ RAG generation pipeline ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b389fa2e",
   "metadata": {},
   "source": [
    "## Part 8: Comparing Results (Before vs. After RAG)\n",
    "\n",
    "Let's test both approaches and compare quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test tender\n",
    "test_tender = \"\"\"Healthcare AI Advisory System\n",
    "\n",
    "National Health Service requires an AI-powered system to provide real-time clinical decision support. \n",
    "The system should analyze patient data, suggest diagnoses, and recommend treatment plans while \n",
    "maintaining full compliance with medical privacy regulations.\n",
    "\n",
    "Budget: ‚Ç¨1.5M\n",
    "Timeline: 12 months\n",
    "Requirements: ISO 27001, HIPAA compliance\"\"\"\n",
    "\n",
    "print(\"üè• Test Tender:\")\n",
    "print(test_tender)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170df110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate WITHOUT RAG\n",
    "print(\"üìÑ Generating WITHOUT RAG...\\n\")\n",
    "doc_without_rag = await generate_without_rag(test_tender)\n",
    "\n",
    "print(\"RESULT (No RAG):\")\n",
    "print(\"=\"*80)\n",
    "print(doc_without_rag)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate WITH RAG\n",
    "print(\"üìÑ Generating WITH RAG...\\n\")\n",
    "doc_with_rag = await generate_with_rag(test_tender)\n",
    "\n",
    "print(\"RESULT (With RAG):\")\n",
    "print(\"=\"*80)\n",
    "print(doc_with_rag)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1041c1",
   "metadata": {},
   "source": [
    "### Quality Comparison\n",
    "\n",
    "Look for these improvements in the RAG version:\n",
    "\n",
    "**Structure**:\n",
    "- ‚ùì Does it follow the example format?\n",
    "- ‚ùì Are sections better organized?\n",
    "\n",
    "**Technical Detail**:\n",
    "- ‚ùì More specific technical approaches?\n",
    "- ‚ùì Concrete numbers and metrics?\n",
    "\n",
    "**Professionalism**:\n",
    "- ‚ùì Sounds more like a real bid?\n",
    "- ‚ùì Addresses compliance explicitly?\n",
    "\n",
    "**Persuasiveness**:\n",
    "- ‚ùì Mentions relevant experience?\n",
    "- ‚ùì Provides reassurance on key concerns?\n",
    "\n",
    "In most cases, RAG versions show significant quality improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b48c0",
   "metadata": {},
   "source": [
    "## Part 9: Measuring RAG Impact\n",
    "\n",
    "We can't just eyeball quality. Let's measure improvement objectively.\n",
    "\n",
    "### Metrics to Track\n",
    "\n",
    "1. **Retrieval Quality**: Are we finding relevant examples?\n",
    "   - Measure: Average similarity score of retrieved docs\n",
    "   - Good: >0.75 similarity\n",
    "\n",
    "2. **Generation Quality**: Is the output better?\n",
    "   - Use LLM-as-judge to rate documents on 1-10 scale\n",
    "   - Compare: with-RAG vs. without-RAG\n",
    "\n",
    "3. **Relevance**: Does generated content incorporate retrieved examples?\n",
    "   - Check for similar terminology/structure\n",
    "\n",
    "Let's implement basic measurement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_rag_quality(tender_description: str, n_tests: int = 3):\n",
    "    \"\"\"Evaluate RAG improvements\"\"\"\n",
    "    \n",
    "    print(f\"üî¨ Running RAG evaluation on {n_tests} test cases...\\n\")\n",
    "    \n",
    "    test_cases = [\n",
    "        \"AI-powered cybersecurity threat detection for government systems\",\n",
    "        \"Custom CRM software development with cloud hosting\",\n",
    "        \"Predictive maintenance AI platform for industrial equipment\"\n",
    "    ][:n_tests]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        print(f\"Test {i}/{n_tests}: {test_case[:60]}...\")\n",
    "        \n",
    "        # Check retrieval quality\n",
    "        search_results = await search_knowledge_base(test_case, n_results=2)\n",
    "        avg_similarity = sum(1 - d for d in search_results['distances'][0]) / len(search_results['distances'][0])\n",
    "        \n",
    "        results.append({\n",
    "            'case': test_case,\n",
    "            'retrieval_similarity': avg_similarity,\n",
    "            'retrieved_categories': [m['category'] for m in search_results['metadatas'][0]]\n",
    "        })\n",
    "        \n",
    "        print(f\"  ‚Üí Retrieval similarity: {avg_similarity:.3f}\")\n",
    "        print(f\"  ‚Üí Retrieved: {', '.join(results[-1]['retrieved_categories'])}\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    avg_ret = sum(r['retrieval_similarity'] for r in results) / len(results)\n",
    "    \n",
    "    print(\"\\nüìä Results:\")\n",
    "    print(f\"  Average retrieval similarity: {avg_ret:.3f}\")\n",
    "    if avg_ret > 0.75:\n",
    "        print(\"  ‚úÖ Excellent retrieval quality!\")\n",
    "    elif avg_ret > 0.65:\n",
    "        print(\"  ‚úì Good retrieval quality\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  Retrieval quality needs improvement\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "eval_results = await evaluate_rag_quality()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e2c8ab",
   "metadata": {},
   "source": [
    "## Part 10: Advanced RAG Techniques (Optional)\n",
    "\n",
    "Our basic RAG is working! Here are enhancements for production:\n",
    "\n",
    "### 1. Metadata Filtering\n",
    "\n",
    "Retrieve only from specific categories:\n",
    "\n",
    "```python\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=3,\n",
    "    where={\"category\": \"cybersecurity\"}  # Filter!\n",
    ")\n",
    "```\n",
    "\n",
    "### 2. Hybrid Search\n",
    "\n",
    "Combine semantic search with keyword matching:\n",
    "- Semantic: Finds conceptually similar docs\n",
    "- Keyword: Ensures specific terms are present\n",
    "\n",
    "### 3. Re-ranking\n",
    "\n",
    "After retrieval, re-rank by:\n",
    "- Recency (prefer newer examples)\n",
    "- Success rate (prefer proven approaches)\n",
    "- Specificity (prefer detailed over generic)\n",
    "\n",
    "### 4. Dynamic k\n",
    "\n",
    "Retrieve variable numbers of examples:\n",
    "- Complex tender ‚Üí More examples (k=3-4)\n",
    "- Simple tender ‚Üí Fewer examples (k=1-2)\n",
    "\n",
    "### 5. Chunk Optimization\n",
    "\n",
    "Instead of whole documents:\n",
    "- Split into sections (executive summary, technical approach, etc.)\n",
    "- Retrieve most relevant sections from different documents\n",
    "- Mix and match best parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc98f06",
   "metadata": {},
   "source": [
    "## Summary: What We Learned\n",
    "\n",
    "### RAG Workflow\n",
    "\n",
    "1. **Build Knowledge Base**: Collect high-quality example documents\n",
    "2. **Create Embeddings**: Convert text to vectors using embedding models\n",
    "3. **Store in Vector DB**: Use ChromaDB for efficient similarity search\n",
    "4. **Retrieve**: Find relevant examples for each new request\n",
    "5. **Augment**: Add examples to LLM prompt\n",
    "6. **Generate**: LLM produces better output informed by examples\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "‚úÖ **Quality Improvement**: Documents match professional standards  \n",
    "‚úÖ **Domain Adaptation**: LLM learns your specific patterns  \n",
    "‚úÖ **Consistency**: Examples ensure similar structure/tone  \n",
    "‚úÖ **Reduced Hallucination**: Grounded in real examples  \n",
    "\n",
    "### When to Use RAG\n",
    "\n",
    "RAG is powerful when:\n",
    "- You have high-quality example documents\n",
    "- Output quality matters (not just correctness)\n",
    "- Domain-specific knowledge is needed\n",
    "- You want to incorporate institutional knowledge\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Now that you understand RAG, we'll:\n",
    "1. Integrate it into the DocumentGenerator agent\n",
    "2. Build a knowledge base management system\n",
    "3. Add evaluation to measure RAG impact\n",
    "4. Deploy to production\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Try these to deepen your understanding:\n",
    "\n",
    "1. **Add more examples**: Create 2-3 more knowledge base entries in different categories\n",
    "\n",
    "2. **Test edge cases**: What happens when you query about a category not in the KB?\n",
    "\n",
    "3. **Experiment with k**: Try n_results=1, 2, 3, 4. How does it affect output?\n",
    "\n",
    "4. **Metadata filtering**: Modify search to only retrieve from one category\n",
    "\n",
    "5. **Quality comparison**: Generate 3 documents (with/without RAG) and compare side-by-side\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook demonstrated RAG fundamentals. In the next phase, we'll build production-ready RAG infrastructure for the procurement system.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
